//tengo:hash_override 8B1CFC68-2542-4C81-8CD4-F927B75F3975

ll := import("@platforma-sdk/workflow-tengo:ll")
self := import("@platforma-sdk/workflow-tengo:tpl")
pConstants := import("@platforma-sdk/workflow-tengo:pframes.constants")
slices := import("@platforma-sdk/workflow-tengo:slices")
maps := import("@platforma-sdk/workflow-tengo:maps")
units := import("@platforma-sdk/workflow-tengo:units")
pt := import("@platforma-sdk/workflow-tengo:pt")

clonotypeLabel := import(":clonotype-label")

math := import("math")
json := import("json")

self.defineOutputs("tsv")

self.body(func(inputs) {
	inputData := inputs[pConstants.VALUE_FIELD_NAME]
	inputDataMeta := inputData.getDataAsJson()

	ll.assert(inputDataMeta.keyLength == 1, "unexpected number of aggregation axes")

	params := inputs.params
	mainAbundanceColumnNormalized := params.mainAbundanceColumnNormalized
	mainAbundanceColumnUnnormalized := params.mainAbundanceColumnUnnormalized

	// { column: string; type: string }
	schemaPerClonotypeNoAggregates := params.schemaPerClonotypeNoAggregates
	schemaPerSample := params.schemaPerSample

	inputMap := inputData.inputs()
	numberOfSamples := len(inputMap)

	memGB := int(math.max(numberOfSamples, 64))
	if !is_undefined(inputs.perProcessMemGB) && inputs.perProcessMemGB > memGB {
		memGB = inputs.perProcessMemGB
	}

	wf := pt.workflow().
		inMediumQueue().
		mem(memGB * units.GiB).
		cpu(int(math.max(numberOfSamples, 32)))

	dataFrames := []

	baseSchemaForRead := schemaPerSample + [ { column: "clonotypeKey", type: "String" } ]

	// ll.print("__THE_LOG__ AGGREGATE BY CLONOTYPE KEY: " + json.encode(maps.getKeys(inputMap)))

	for sKey in maps.getKeys(inputMap) {
		inputFile := inputMap[sKey]
		key := json.decode(sKey)
		if len(key) != 1 {
			ll.panic("malformed key: %v", sKey)
		}
		sampleId := key[0]
		dfId := "table_" + sampleId

		df := wf.frame({
			file: inputFile,
			xsvType: "tsv",
			schema: baseSchemaForRead
		}, {
			id: dfId,
			inferSchema: false
		})
		dataFrames = append(dataFrames, df)
	}

	currentDf := undefined
	if len(dataFrames) == 0 {
		ll.panic("no input files found")
	} else if len(dataFrames) == 1 {
		currentDf = dataFrames[0]
	} else {
		currentDf = pt.concat(dataFrames)
	}

	aggExpressions := []

	for colDef in schemaPerClonotypeNoAggregates {
		if colDef.column == "clonotypeLabel" || colDef.column == "nLengthTotalAdded" {
			continue
		}
		aggExpressions = append(aggExpressions,
			pt.col(colDef.column).maxBy(pt.col(mainAbundanceColumnNormalized)).alias(colDef.column)
		)
	}

	aggExpressions = append(aggExpressions,
		pt.col(mainAbundanceColumnNormalized).count().alias("sampleCount"),
		pt.col(mainAbundanceColumnUnnormalized).sum().alias(mainAbundanceColumnUnnormalized + "Sum"),
		pt.col(mainAbundanceColumnNormalized).mean().alias(mainAbundanceColumnNormalized + "Mean")
	)

	aggregatedDf := currentDf.groupBy("clonotypeKey").agg(aggExpressions...)

	// Calculate total added nucleotides: VDJunction + DJJunction for chains with D genes, VJJunction for chains without D genes
	aggregatedDf = aggregatedDf.withColumns(
		pt.when(pt.col("nLengthVDJunction").isNotNull().and(pt.col("nLengthVDJunction").neq("no_d_gene"))).
			then(pt.col("nLengthVDJunction").cast("Int").plus(pt.col("nLengthDJJunction").cast("Int"))).
			otherwise(pt.col("nLengthVJJunction").cast("Int")).
			alias("nLengthTotalAdded")
	)

	aggregatedDf = clonotypeLabel.addClonotypeLabelColumnsPt(aggregatedDf, "clonotypeKey", "clonotypeLabel", pt)

	aggregatedDf.save("output.tsv")

	ptablerResult := wf.run()

	processedTsv := ptablerResult.getFile("output.tsv")

	return {
		tsv: processedTsv
	}
})
